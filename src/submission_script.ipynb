{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from config import model_name\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os import path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import importlib\n",
    "from multiprocessing import Pool\n",
    "\n",
    "try:\n",
    "    Model = getattr(importlib.import_module(f\"model.{model_name}\"), model_name)\n",
    "    config = getattr(importlib.import_module('config'), f\"{model_name}Config\")\n",
    "except AttributeError:\n",
    "    print(f\"{model_name} not included!\")\n",
    "    exit()\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RESULT_CSV = 'results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2**y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)\n",
    "\n",
    "\n",
    "def value2rank(d):\n",
    "    values = list(d.values())\n",
    "    ranks = [sorted(values, reverse=True).index(x) for x in values]\n",
    "    return {k: ranks[i] + 1 for i, k in enumerate(d.keys())}\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load news for evaluation.\n",
    "    \"\"\"\n",
    "    def __init__(self, news_path):\n",
    "        super(NewsDataset, self).__init__()\n",
    "        self.news_parsed = pd.read_table(\n",
    "            news_path,\n",
    "            usecols=['id'] + config.dataset_attributes['news'],\n",
    "            converters={\n",
    "                attribute: literal_eval\n",
    "                for attribute in set(config.dataset_attributes['news']) & set([\n",
    "                    'title', 'abstract', 'title_entities', 'abstract_entities'\n",
    "                ])\n",
    "            })\n",
    "        self.news2dict = self.news_parsed.to_dict('index')\n",
    "        for key1 in self.news2dict.keys():\n",
    "            for key2 in self.news2dict[key1].keys():\n",
    "                if type(self.news2dict[key1][key2]) != str:\n",
    "                    self.news2dict[key1][key2] = torch.tensor(\n",
    "                        self.news2dict[key1][key2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.news_parsed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.news2dict[idx]\n",
    "        return item\n",
    "\n",
    "\n",
    "class UserDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load users for evaluation, duplicated rows will be dropped\n",
    "    \"\"\"\n",
    "    def __init__(self, behaviors_path, user2int_path):\n",
    "        super(UserDataset, self).__init__()\n",
    "        self.behaviors = pd.read_table(behaviors_path,\n",
    "                                       header=None,\n",
    "                                       usecols=[1, 3],\n",
    "                                       names=['user', 'clicked_news'])\n",
    "        self.behaviors.clicked_news.fillna(' ', inplace=True)\n",
    "        self.behaviors.drop_duplicates(inplace=True)\n",
    "        user2int = dict(pd.read_table(user2int_path).values.tolist())\n",
    "        user_total = 0\n",
    "        user_missed = 0\n",
    "        for row in self.behaviors.itertuples():\n",
    "            user_total += 1\n",
    "            if row.user in user2int:\n",
    "                self.behaviors.at[row.Index, 'user'] = user2int[row.user]\n",
    "            else:\n",
    "                user_missed += 1\n",
    "                self.behaviors.at[row.Index, 'user'] = 0\n",
    "        if model_name == 'LSTUR':\n",
    "            print(f'User miss rate: {user_missed/user_total:.4f}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.behaviors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.behaviors.iloc[idx]\n",
    "        item = {\n",
    "            \"user\":\n",
    "            row.user,\n",
    "            \"clicked_news_string\":\n",
    "            row.clicked_news,\n",
    "            \"clicked_news\":\n",
    "            row.clicked_news.split()[:config.num_clicked_news_a_user]\n",
    "        }\n",
    "        item['clicked_news_length'] = len(item[\"clicked_news\"])\n",
    "        repeated_times = config.num_clicked_news_a_user - len(\n",
    "            item[\"clicked_news\"])\n",
    "        assert repeated_times >= 0\n",
    "        item[\"clicked_news\"] = ['PADDED_NEWS'\n",
    "                                ] * repeated_times + item[\"clicked_news\"]\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "class BehaviorsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load behaviors for evaluation, (user, time) pair as session\n",
    "    \"\"\"\n",
    "    def __init__(self, behaviors_path):\n",
    "        super(BehaviorsDataset, self).__init__()\n",
    "        self.behaviors = pd.read_table(behaviors_path,\n",
    "                                       header=None,\n",
    "                                       usecols=range(5),\n",
    "                                       names=[\n",
    "                                           'impression_id', 'user', 'time',\n",
    "                                           'clicked_news', 'impressions'\n",
    "                                       ])\n",
    "        self.behaviors.clicked_news.fillna(' ', inplace=True)\n",
    "        self.behaviors.impressions = self.behaviors.impressions.str.split()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.behaviors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.behaviors.iloc[idx]\n",
    "        item = {\n",
    "            \"impression_id\": row.impression_id,\n",
    "            \"user\": row.user,\n",
    "            \"time\": row.time,\n",
    "            \"clicked_news_string\": row.clicked_news,\n",
    "            \"impressions\": row.impressions\n",
    "        }\n",
    "        return item\n",
    "\n",
    "\n",
    "def calculate_single_user_metric(pair):\n",
    "    try:\n",
    "        auc = roc_auc_score(*pair)\n",
    "        mrr = mrr_score(*pair)\n",
    "        ndcg5 = ndcg_score(*pair, 5)\n",
    "        ndcg10 = ndcg_score(*pair, 10)\n",
    "        return [auc, mrr, ndcg5, ndcg10]\n",
    "    except ValueError:\n",
    "        return [np.nan] * 4\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, directory, num_workers, max_count=sys.maxsize, mode='test'):\n",
    "    \"\"\"\n",
    "    Evaluate model on target directory.\n",
    "    Args:\n",
    "        model: model to be evaluated\n",
    "        directory: the directory that contains two files (behaviors.tsv, news_parsed.tsv)\n",
    "        num_workers: processes number for calculating metrics\n",
    "    Returns:\n",
    "        AUC\n",
    "        MRR\n",
    "        nDCG@5\n",
    "        nDCG@10\n",
    "    \"\"\"\n",
    "    news_dataset = NewsDataset(path.join(directory, 'news_parsed.tsv'))\n",
    "    news_dataloader = DataLoader(news_dataset,\n",
    "                                 batch_size=config.batch_size * 16,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=config.num_workers,\n",
    "                                 drop_last=False,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    news2vector = {}\n",
    "    for minibatch in tqdm(news_dataloader,\n",
    "                          desc=\"Calculating vectors for news\"):\n",
    "        news_ids = minibatch[\"id\"]\n",
    "        if any(id not in news2vector for id in news_ids):\n",
    "            news_vector = model.get_news_vector(minibatch)\n",
    "            for id, vector in zip(news_ids, news_vector):\n",
    "                if id not in news2vector:\n",
    "                    news2vector[id] = vector\n",
    "\n",
    "    news2vector['PADDED_NEWS'] = torch.zeros(\n",
    "        list(news2vector.values())[0].size())\n",
    "\n",
    "    user_dataset = UserDataset(path.join(directory, 'behaviors.tsv'),\n",
    "                               'data/train/user2int.tsv')\n",
    "    user_dataloader = DataLoader(user_dataset,\n",
    "                                 batch_size=config.batch_size * 16,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=config.num_workers,\n",
    "                                 drop_last=False,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    user2vector = {}\n",
    "    for minibatch in tqdm(user_dataloader,\n",
    "                          desc=\"Calculating vectors for users\"):\n",
    "        user_strings = minibatch[\"clicked_news_string\"]\n",
    "        if any(user_string not in user2vector for user_string in user_strings):\n",
    "            clicked_news_vector = torch.stack([\n",
    "                torch.stack([news2vector[x].to(device) for x in news_list],\n",
    "                            dim=0) for news_list in minibatch[\"clicked_news\"]\n",
    "            ],\n",
    "                                              dim=0).transpose(0, 1)\n",
    "            if model_name == 'LSTUR':\n",
    "                user_vector = model.get_user_vector(\n",
    "                    minibatch['user'], minibatch['clicked_news_length'],\n",
    "                    clicked_news_vector)\n",
    "            else:\n",
    "                user_vector = model.get_user_vector(clicked_news_vector)\n",
    "            for user, vector in zip(user_strings, user_vector):\n",
    "                if user not in user2vector:\n",
    "                    user2vector[user] = vector\n",
    "\n",
    "    behaviors_dataset = BehaviorsDataset(path.join(directory, 'behaviors.tsv'))\n",
    "    behaviors_dataloader = DataLoader(behaviors_dataset,\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=config.num_workers)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    tasks = []\n",
    "    result_dict = {}\n",
    "\n",
    "    for minibatch in tqdm(behaviors_dataloader,\n",
    "                          desc=\"Calculating probabilities\"):\n",
    "        count += 1\n",
    "        if count == max_count:\n",
    "            break\n",
    "\n",
    "        candidate_news_vector = torch.stack([\n",
    "            news2vector[news[0].split('-')[0]]\n",
    "            for news in minibatch['impressions']\n",
    "        ],\n",
    "                                            dim=0)\n",
    "        user_vector = user2vector[minibatch['clicked_news_string'][0]]\n",
    "        click_probability = model.get_prediction(candidate_news_vector,\n",
    "                                                 user_vector)\n",
    "\n",
    "        y_pred = click_probability.tolist()\n",
    "        if mode == 'train':\n",
    "            y_true = [\n",
    "                int(news[0].split('-')[1]) for news in minibatch['impressions']\n",
    "            ]\n",
    "            tasks.append((y_true, y_pred))\n",
    "        elif mode == 'test':\n",
    "            result_dict[f'{count-1}'] = y_pred\n",
    "\n",
    "    if mode == 'train':\n",
    "        with Pool(processes=num_workers) as pool:\n",
    "            results = pool.map(calculate_single_user_metric, tasks)\n",
    "\n",
    "        aucs, mrrs, ndcg5s, ndcg10s = np.array(results).T\n",
    "        return np.nanmean(aucs), np.nanmean(mrrs), np.nanmean(ndcg5s), np.nanmean(\n",
    "            ndcg10s)\n",
    "    elif mode == 'test':\n",
    "        return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n",
      "Evaluating model NRMS\n",
      "Load saved parameters in ./checkpoint/NRMS/ckpt-7000.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712b7982f7cc4b72a250eae0e3a12d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for news:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7535b516a4144a50bba6ed2dc9d8a47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for users:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6a98800714435c9d1b3147decb7593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating probabilities:   0%|          | 0/285297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7214\n",
      "MRR: 0.3908\n",
      "nDCG@5: 0.4670\n",
      "nDCG@10: 0.5635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8bee87f3b24125a0f482ca64262f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for news:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f179fd00eafe4a85a0f99b748da51992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for users:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da34016175974b34b3aa7209f37ad235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating probabilities:   0%|          | 0/46332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Using device:', device)\n",
    "print(f'Evaluating model {model_name}')\n",
    "# Don't need to load pretrained word/entity/context embedding\n",
    "# since it will be loaded from checkpoint later\n",
    "model = Model(config).to(device)\n",
    "from train import latest_checkpoint  # Avoid circular imports\n",
    "checkpoint_path = latest_checkpoint(path.join('./checkpoint', model_name))\n",
    "if checkpoint_path is None:\n",
    "    print('No checkpoint file found!')\n",
    "    exit()\n",
    "print(f\"Load saved parameters in {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "auc, mrr, ndcg5, ndcg10 = evaluate(model, './data/val',\n",
    "                                   config.num_workers, mode='train')\n",
    "print(\n",
    "    f'AUC: {auc:.4f}\\nMRR: {mrr:.4f}\\nnDCG@5: {ndcg5:.4f}\\nnDCG@10: {ndcg10:.4f}'\n",
    ")\n",
    "\n",
    "y_preds = evaluate(model, './data/test', config.num_workers, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12</th>\n",
       "      <th>p13</th>\n",
       "      <th>p14</th>\n",
       "      <th>p15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.183794</td>\n",
       "      <td>-0.797354</td>\n",
       "      <td>-0.536473</td>\n",
       "      <td>2.165243</td>\n",
       "      <td>-1.153278</td>\n",
       "      <td>0.298964</td>\n",
       "      <td>0.202679</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>-0.706279</td>\n",
       "      <td>-0.686258</td>\n",
       "      <td>-0.701948</td>\n",
       "      <td>-0.136578</td>\n",
       "      <td>-0.735354</td>\n",
       "      <td>0.078419</td>\n",
       "      <td>0.946975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.206575</td>\n",
       "      <td>-0.225023</td>\n",
       "      <td>-0.013934</td>\n",
       "      <td>-0.543442</td>\n",
       "      <td>0.342222</td>\n",
       "      <td>-0.418650</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>-0.142107</td>\n",
       "      <td>0.327512</td>\n",
       "      <td>0.308264</td>\n",
       "      <td>-0.313714</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>-0.097447</td>\n",
       "      <td>-0.326808</td>\n",
       "      <td>-0.135655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.073174</td>\n",
       "      <td>0.357276</td>\n",
       "      <td>0.168952</td>\n",
       "      <td>-0.342357</td>\n",
       "      <td>-0.113186</td>\n",
       "      <td>-0.101083</td>\n",
       "      <td>-0.079423</td>\n",
       "      <td>-0.317790</td>\n",
       "      <td>0.096257</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>0.153774</td>\n",
       "      <td>-0.267926</td>\n",
       "      <td>-0.383316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.258743</td>\n",
       "      <td>-0.202310</td>\n",
       "      <td>-0.040910</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>-0.165550</td>\n",
       "      <td>0.129389</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>-0.112855</td>\n",
       "      <td>-0.392836</td>\n",
       "      <td>-0.017779</td>\n",
       "      <td>-0.301390</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.085155</td>\n",
       "      <td>-0.301782</td>\n",
       "      <td>0.120205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.103027</td>\n",
       "      <td>0.468785</td>\n",
       "      <td>-0.191371</td>\n",
       "      <td>0.376598</td>\n",
       "      <td>-0.245778</td>\n",
       "      <td>-0.015998</td>\n",
       "      <td>-0.164391</td>\n",
       "      <td>0.301599</td>\n",
       "      <td>-0.297742</td>\n",
       "      <td>-1.032542</td>\n",
       "      <td>-1.205259</td>\n",
       "      <td>-0.276209</td>\n",
       "      <td>0.342670</td>\n",
       "      <td>0.125423</td>\n",
       "      <td>-0.317054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46327</th>\n",
       "      <td>46327</td>\n",
       "      <td>-0.458541</td>\n",
       "      <td>-0.149874</td>\n",
       "      <td>0.318461</td>\n",
       "      <td>0.045217</td>\n",
       "      <td>-0.128579</td>\n",
       "      <td>0.131929</td>\n",
       "      <td>-0.297343</td>\n",
       "      <td>-0.279712</td>\n",
       "      <td>-0.204995</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>-0.285336</td>\n",
       "      <td>0.289681</td>\n",
       "      <td>0.048688</td>\n",
       "      <td>-0.187876</td>\n",
       "      <td>-0.360425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46328</th>\n",
       "      <td>46328</td>\n",
       "      <td>-0.224928</td>\n",
       "      <td>-0.050704</td>\n",
       "      <td>-0.032955</td>\n",
       "      <td>0.035137</td>\n",
       "      <td>-0.103648</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>-0.053892</td>\n",
       "      <td>-0.038986</td>\n",
       "      <td>-0.062810</td>\n",
       "      <td>0.036746</td>\n",
       "      <td>-0.083936</td>\n",
       "      <td>0.264135</td>\n",
       "      <td>-0.352102</td>\n",
       "      <td>-0.076280</td>\n",
       "      <td>0.016065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46329</th>\n",
       "      <td>46329</td>\n",
       "      <td>-0.306582</td>\n",
       "      <td>-0.486910</td>\n",
       "      <td>1.141995</td>\n",
       "      <td>0.058732</td>\n",
       "      <td>-0.785894</td>\n",
       "      <td>0.585979</td>\n",
       "      <td>-0.485143</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>1.272189</td>\n",
       "      <td>-0.688220</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>-0.340864</td>\n",
       "      <td>-0.777608</td>\n",
       "      <td>0.144943</td>\n",
       "      <td>-0.004685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46330</th>\n",
       "      <td>46330</td>\n",
       "      <td>0.576961</td>\n",
       "      <td>-0.886301</td>\n",
       "      <td>-0.066326</td>\n",
       "      <td>0.387231</td>\n",
       "      <td>-0.802487</td>\n",
       "      <td>-0.799435</td>\n",
       "      <td>-0.278686</td>\n",
       "      <td>-0.222543</td>\n",
       "      <td>-0.072449</td>\n",
       "      <td>-0.762129</td>\n",
       "      <td>-1.171261</td>\n",
       "      <td>-0.125202</td>\n",
       "      <td>-0.942808</td>\n",
       "      <td>-0.049369</td>\n",
       "      <td>-0.323195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46331</th>\n",
       "      <td>46331</td>\n",
       "      <td>-0.429203</td>\n",
       "      <td>0.073607</td>\n",
       "      <td>-0.011281</td>\n",
       "      <td>-0.429557</td>\n",
       "      <td>0.228963</td>\n",
       "      <td>0.289643</td>\n",
       "      <td>0.143261</td>\n",
       "      <td>-0.068777</td>\n",
       "      <td>-0.260234</td>\n",
       "      <td>-0.065809</td>\n",
       "      <td>-0.123314</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.064695</td>\n",
       "      <td>0.334313</td>\n",
       "      <td>0.017217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46332 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        p1        p2        p3        p4        p5        p6  \\\n",
       "0          0  1.183794 -0.797354 -0.536473  2.165243 -1.153278  0.298964   \n",
       "1          1  0.206575 -0.225023 -0.013934 -0.543442  0.342222 -0.418650   \n",
       "2          2  0.073174  0.357276  0.168952 -0.342357 -0.113186 -0.101083   \n",
       "3          3  0.258743 -0.202310 -0.040910  0.029026 -0.165550  0.129389   \n",
       "4          4 -1.103027  0.468785 -0.191371  0.376598 -0.245778 -0.015998   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "46327  46327 -0.458541 -0.149874  0.318461  0.045217 -0.128579  0.131929   \n",
       "46328  46328 -0.224928 -0.050704 -0.032955  0.035137 -0.103648  0.018052   \n",
       "46329  46329 -0.306582 -0.486910  1.141995  0.058732 -0.785894  0.585979   \n",
       "46330  46330  0.576961 -0.886301 -0.066326  0.387231 -0.802487 -0.799435   \n",
       "46331  46331 -0.429203  0.073607 -0.011281 -0.429557  0.228963  0.289643   \n",
       "\n",
       "             p7        p8        p9       p10       p11       p12       p13  \\\n",
       "0      0.202679  0.011402 -0.706279 -0.686258 -0.701948 -0.136578 -0.735354   \n",
       "1      0.058411 -0.142107  0.327512  0.308264 -0.313714  0.035650 -0.097447   \n",
       "2     -0.079423 -0.317790  0.096257  0.160641  0.187640 -0.139982  0.153774   \n",
       "3     -0.019053 -0.112855 -0.392836 -0.017779 -0.301390  0.012729  0.085155   \n",
       "4     -0.164391  0.301599 -0.297742 -1.032542 -1.205259 -0.276209  0.342670   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "46327 -0.297343 -0.279712 -0.204995 -0.005381 -0.285336  0.289681  0.048688   \n",
       "46328 -0.053892 -0.038986 -0.062810  0.036746 -0.083936  0.264135 -0.352102   \n",
       "46329 -0.485143  0.024705  1.272189 -0.688220  0.417800 -0.340864 -0.777608   \n",
       "46330 -0.278686 -0.222543 -0.072449 -0.762129 -1.171261 -0.125202 -0.942808   \n",
       "46331  0.143261 -0.068777 -0.260234 -0.065809 -0.123314  0.000651  0.064695   \n",
       "\n",
       "            p14       p15  \n",
       "0      0.078419  0.946975  \n",
       "1     -0.326808 -0.135655  \n",
       "2     -0.267926 -0.383316  \n",
       "3     -0.301782  0.120205  \n",
       "4      0.125423 -0.317054  \n",
       "...         ...       ...  \n",
       "46327 -0.187876 -0.360425  \n",
       "46328 -0.076280  0.016065  \n",
       "46329  0.144943 -0.004685  \n",
       "46330 -0.049369 -0.323195  \n",
       "46331  0.334313  0.017217  \n",
       "\n",
       "[46332 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_to_submit = pd.DataFrame(y_preds).T\n",
    "results_to_submit.to_csv(\n",
    "  'results.csv',\n",
    "  header=[\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\", \"p9\", \"p10\", \"p11\", \"p12\", \"p13\", \"p14\", \"p15\"],\n",
    "  index_label='index'\n",
    "  )\n",
    "\n",
    "# results_to_submit.columns = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\", \"p9\", \"p10\", \"p11\", \"p12\", \"p13\", \"p14\", \"p15\"]\n",
    "\n",
    "# results_to_submit\n",
    "\n",
    "pd.read_csv(RESULT_CSV, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定義需要的log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BaseConfig\n",
    "\n",
    "num_epochs = BaseConfig.num_epochs\n",
    "# Number of batchs to show loss\n",
    "num_batches_show_loss = BaseConfig.num_batches_show_loss\n",
    "# Number of batchs to check metrics on validation dataset\n",
    "num_batches_validate = BaseConfig.num_batches_validate\n",
    "batch_size = BaseConfig.batch_size\n",
    "learning_rate = BaseConfig.learning_rate\n",
    "# Number of workers for data loading\n",
    "num_workers = BaseConfig.num_workers\n",
    "# Number of sampled click history for each user\n",
    "num_clicked_news_a_user = BaseConfig.num_clicked_news_a_user\n",
    "num_words_title = BaseConfig.num_words_title\n",
    "num_words_abstract = BaseConfig.num_words_abstract\n",
    "word_freq_threshold = BaseConfig.word_freq_threshold\n",
    "entity_freq_threshold = BaseConfig.entity_freq_threshold\n",
    "entity_confidence_threshold = BaseConfig.entity_confidence_threshold\n",
    "# K\n",
    "negative_sampling_ratio = BaseConfig.negative_sampling_ratio\n",
    "dropout_probability = BaseConfig.dropout_probability\n",
    "# Modify the following by the output of `src/dataprocess.py`\n",
    "num_words = BaseConfig.num_words\n",
    "num_categories = BaseConfig.num_categories\n",
    "num_entities = BaseConfig.num_entities\n",
    "num_users = BaseConfig.num_users\n",
    "word_embedding_dim = BaseConfig.word_embedding_dim\n",
    "category_embedding_dim = BaseConfig.category_embedding_dim\n",
    "# Modify the following only if you use another dataset\n",
    "entity_embedding_dim = BaseConfig.entity_embedding_dim\n",
    "# For additive attention\n",
    "query_vector_dim = BaseConfig.query_vector_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle competitions submit -c 2023-datamining-final-project -f results.csv -m \"AUC: 0.7214, MRR: 0.3908, nDCG@5: 0.4670, nDCG@10: 0.5635  *EXTRA: [].\"\n"
     ]
    }
   ],
   "source": [
    "EXTRA_MSG: str = ('' + \\\n",
    "  # f'SMOTE+RANDOM stacking ' + \\\n",
    "\n",
    "  # f'take away age>=90 from training data ' + \\\n",
    "  # f'ratio=(8, 2) ' + \\\n",
    "  # f'with normalization ({norm_mode=}) ' + \\\n",
    "  # f'Logistic Regression!' + \\\n",
    "  '')\n",
    "\n",
    "# if REMOVE_MISMATCH:\n",
    "#   EXTRA_MSG += f' | {REMOVE_MISMATCH=}, '\n",
    "# if REFINE_CAPITAL_DIFF:\n",
    "#   EXTRA_MSG += f' | {REFINE_CAPITAL_DIFF=}, '\n",
    "# if REFINE_AGE:\n",
    "#   EXTRA_MSG += f' | {REFINE_AGE=}, '\n",
    "# if REFINE_HPWEEK:\n",
    "#   EXTRA_MSG += f' | {REFINE_HPWEEK=}, '\n",
    "# if REFINE_RACE:\n",
    "#   EXTRA_MSG += f' | {REFINE_RACE=}, '\n",
    "\n",
    "log = (\n",
    "  f\"kaggle competitions submit -c 2023-datamining-final-project -f {RESULT_CSV} -m \"\n",
    "  # f'''\"Features: {best_config['feature']}. INFO: '''\n",
    "  f'''\"AUC: {auc:.4f}, MRR: {mrr:.4f}, nDCG@5: {ndcg5:.4f}, nDCG@10: {ndcg10:.4f}''' \n",
    "  # [Acc={acc:.4f}, iteration={best_config['iteration']}, lr={best_config['lr']:.6f}, {l2_lambda=:.3f}] \n",
    "  f'''  *EXTRA: [{EXTRA_MSG}].\"'''\n",
    ")\n",
    "print(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submmit to the Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:03<00:00, 3.66MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to 2023 Data Mining Final Project"
     ]
    }
   ],
   "source": [
    "# For safty.\n",
    "import os\n",
    "# raise KeyError('Are you sure you want to submit the result?')\n",
    "_ = os.system(log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
